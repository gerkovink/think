[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Generative AI in Higher Education",
    "section": "",
    "text": "Note\n\n\n\nThe slides for the introduction can be found here\n\n\n\nIntroduction\nIn the last 3 years, the development of generative artificial intelligence (AI) has taken a steep rise. But AI is no new idea. Ever sinds Alan Turing’s seminal lecture on the automatic computing machine (Turing 2004), computer scientists have worked towards the realization of artificial intelligence. Even AI chatbots are not new. In 1966,Joseph Weizenbaum developed the psychotherapist chatbot ELIZA (Weizenbaum 1966). I am not going to give an overview of the history of AI, as others have already created a far better overview than I could ever create - see e.g. this link, Wikipedia or this overview. Bottom line, ever since the development of GitHub Copilot in 2021, the field of generative AI has rapidly become accessible to a broader audience. This development has a direct impact on higher education, as the straightforward access for student and teacher populations to generative AI has the potential to impact education, research and policy. Developments in generative AI also have the means to create new opportunities and - unfortunately - new divides.\n\n\nRules of Engagement\nYou may use anything I present to you as input into generative AI tools, with the exeption of using my content and materials for training purposes. This means that you should opt-out of training if you’d like to copy-paste or upload these materials into an AI tool input window.\nFurther, you may use AI-generated output during the challenges. But you should redact it and you must take full responsibility for the output’s veracity, correctness and any output you use should be free of IP and copyright infringement. If you’d like a set of suggestions on how to use AI tools in a responsible manner, please look at these suggestions to embed generative AI in Academia that I have collected and motivated.\n\n\nChallenges\nIn the below panel, I have formulated three challenges for you to collaborate on. The aim of the challenges is to learn from your perspective and insights. I know many people in academia who think, act and work as educators. They approach the challenges presented here from a certain viewpoint, which mostly is related to protecting the status quo. While this can be a good thing, certainly in the short run, I do believe that adopting a more robust frame of mind will eventually lead to better integration of AI tools in our academic activities. For that goal, we need your voice! I am curious to see how your beliefs, values and experience can contribute to this transition.\nLet’s start.\n\n1: No output without input2: Rethinking Grading3: Hidden Impact\n\n\nIn this challenge you will write a letter of advice to either students, teachers or the Exam Committee. But before we get into this, I’d like to frame your mind with some additional information.\nFirst, I recently wrote the text in the below callout box. Please read it.\n\n\n\n\n\n\nDo you know your input rights?\n\n\n\nAt Utrecht University we hold ethics, honesty, and the values of open science in the highest regard. These principles are the backbone of our academic community and guide our education as well as our pursuit of knowledge.\nNow that AI tools become more advanced and widespread, it is crucial to uphold these values. While much focus has been on the output of AI tools, I want to bring attention to a different concern: the unjust use of what we input into these tools.\nMany of us interact with AI in what feels like the privacy of our own devices. This perceived privacy can create a false sense of security, leading some to input information that was not theirs to share or should have remained confidential. To safeguard our integrity and respect intellectual property rights, we must be cautious about what we share with AI tools. Specifically:\n\nDo not input assignments, course materials, scientific manuscripts or any other work without explicit permission from the owners.\nAvoid using AI tools to grade or evaluate each other’s work unless you have the author’s consent.\n\nBy following these guidelines, we protect and respect both the creative efforts and the intellectual property in our community.\n\n\nThe prime reason for writing this text is that I come across more and more community members that are unaware of the dangers of inputting information into AI tools. I have seen students use AI tools to generate text for assignments that they have also uploaded to AI tools in the same process. I have seen teachers use AI tools to assess or provide feedback to student work, and researchers that use AI tools to review scientific manuscripts. While these tools can be very helpful, they can also be very harmful if not used correctly and the perceived privacy of the own device &lt;-&gt; tool interaction may lull the user into a false sense of security.\nKumar (2023) wrote a wonderful case study about a hypothetical professor that used an AI tool to grade student work. The case study highlights many of the issues involved and I can highly recommend reading the publication. While Kumar (2023) focuses on a faculty member, this behavior is not unique to teachers and instructors alike. Students, researchers, and staff members can all fall into the same trap. This challenge will therefore focus on both AI input and output.\nSecond, according to our own university’s website, the current education and examination regulations (OER) already provides the right guideline which is also compliant with the introduction of GenAI (Utrecht University 2024b). This source also reads the following UU-wide policy:\n\nUtrecht University has the following guidelines regarding generative AI (GenAI): Students may use GenAI if the lecturer indicates that this is allowed. The student must follow the rules indicated by the lecturer about the ways in which it may and may not be used and how it should be referenced. Tools are being developed to clarify for lecturers what choices can be made, so that these choices are properly and clearly communicated to students. Students are never allowed to submit work developed entirely by GenAI as their own. If this does happen, it is considered fraud, see the Education and examination regulations (OER) below. Source: Utrecht University (2024b)\n\nNow that we have considered these two sources, I would like to present you with the first challenge.\n\nDefinition of Challenge\nAt Utrecht we hold core scientific values like honesty and opennes in the highest regard (Utrecht University 2024a; KNAW et al. 2018). Consider this when you read the following two scenarios\n\nA student is aware of AI hallucinations and creates a custom GPT by uploading all relevant course materials, including the reader, articles and book, into an AI tool. Based on these materials, the students also feeds the custom GPT the course assignments, and redacts the generated output to complete the course assignments. The student refers to all the trained materials and hands in the final product under their own name. The teacher grades the material and suspects that the student has used AI tools more comprehensively than the teacher has intended. However, the only communiqué by the teacher was “you can use generative AI”.\nA teacher uses a generative AI tool to efficiently give feedback to student work and, later in the process, uses AI to grade student work by automatically scoring the assignments with an AI tool. The teacher then grades by hand all the assignments that were AI-graded lower than 6, and randomly selects some of the other assignments to also double check. As a final grade, the students whose work is double-checked by the teacher will always receive the teacher’s grade - even if it is a lower mark. The teacher has not informed the students about the use of AI for grading, nor has the teacher asked for permission to use the tool.\n\nIn both scenarios, the Exam Committee has been contacted with a complaint. In scenario 1, the teacher complains about their suspicions of the student’s approach, and in scenario 2 a student has contacted the exam committee with their suspicions about the teacher’s grading approach. Divide your team into 4 groups. Each group will work on one scenario and represent either the teacher/student or the exam committee in the following scheme:\n\nGroup A: Teacher in Scenario 1\nGroup B: Exam Committee in Scenario 1\nGroup C: Student in Scenario 2\nGroup D: Exam Committee in Scenario 2\n\nEach group will discuss the following questions:\n\nEthical implications of the two scenarios. What are the potential harms and benefits of using AI in these ways? What are the potential consequences for the student, teacher, and the academic community?\n*Legal implications of the scenario. What are the potential legal consequences for the student, teacher, and the academic community?\nEducational implications of the scenario. How do these scenarios affect the learning process? Like before, are there potential consequences for the student, teacher, and the academic community?\nPolicy implications of the scenario. What are the potential policy changes that could prevent these scenarios from happening in the future? Again, what are the potential consequences for the student, teacher, and the academic community?\nHow could the communication between the student, teacher, and the exam committee have been improved to prevent these scenarios from happening in the future?\n\nAfter discussing these questions, each group will write a letter of advice to the opposite body. So, if you represent the teacher in scenario 1, you write an advice to the Exam Committee - and vice versa. You letter should\n\ndemonstrate briefly your understanding of the motivation of the actions in the scenario - i.e. I know why they did it!\nadvice on how to improve policy/communication/education at our university to avoid further conflict about this scenario in the future.\nany other business that came up in your discussion that you think is important to mention\n\nA good advice here is to focus on what the other party should have done to prevent this scenario, don’t focus too much on what should not have been done in the scenario’s. If you’d like to focus on a broader class of scenario’s - that’s fine too.\n\n\n\nIt is hard to deny that AI tools have the potential to revolutionize the way we humans work and learn together. Some people argue that we are currently in a transition phase, where our whole economic system of valuation, skills and merit will transition to a more crafty, creative and human-centered system. Others argue that we are in a phase of automation, where the human touch is lost and the value of human work is diminished. Nevertheless, the use of AI tools in education is a hot topic and the community’s drive for experimentation and innovation is high.\nThis means that teachers and students alike are experimenting with AI tools in their daily work. While these tools are argued to potentially become very helpful in the realm of learning (Roschelle, Lester, and Fusco 2020), signs are coming in that contemporary use may do more damage than good (Abbas, Jam, and Khan 2024; Habib et al. 2024; Heersmink 2024). But this damage may come from the way we use these tools, not from the tools themselves. Perhaps we are trying to fit a square peg into a round hole.\nThere is a finite number of options for dealing with generative AI in education. These options translate to the following stages of what I like to call AI grief with respect to validly assessing student performance:\n\nIgnore the existence of generative AI\nForbid the use of generative AI\nCircumnavigate generative AI by using offline assessment modes like pen/paper exams or oral exams\nTest around the shortcomings of contemporary AI and let students perform tasks that generative AI struggles with\nEmbrace generative AI and allow it in course work\nRethink the way we assess students and develop new assessment methodologies\n\nStages 1 and 2 are not realistic anymore. That ship has sailed. Stage 4 is also not a proper robust way of dealing with AI, because what does not work today may be well-implemented tomorrow. It is reasonable to expect that that in the forseeable future, our grading practice will iterate over stages 3, 5 and 6, where we will see a mix of traditional and AI-allowed assessment.\nIn this challenge, I would like to focus on a valid future-robust grading practice. Because the grading process is a crucial part of the learning process - the point where it is evaluated if the student has met the learning goals - it is important to ensure that this process remains valid.\n\nDefinition of Challenge\nIn this challenge, you will work towards a future-robust grading practice that you deem fair, valid and reliable.\n1. Do this step individually: Imagine a course that you thoroughly enjoyed and for which you expect that AI would perform well if it were a student. Look it up on Osiris, to be able to fill in the details if necessary. Use the following priming questions to frame your mind:\n\nWhat are the learning goals of the course? How do these learning goals translate to the assessment of the course? What assessment methods are used?\nDo you think that the assessment aligns with the learning goals?\nDoes your answer for to the previous question change if you consider the use of AI in the assessment? If so, Do you think that theproblem lies with the assessment methods or with the learning goals/aims of the course?\nDo you think that the assesment methods used are vulnerable to the use of AI by students? How would you rank them in terms of vulnerability?\nDo you think that a different assessment method would be more suitable for the learning goals of the course? If so, what method would you propose?\nWere/are you allowed to use AI tools in the coursework of the course? If so, what tools were allowed and what were the rules/limitations? If not, do you believe that students used AI tools anyway?\nDo you see potential benefits of students’ using AI in making the coursework? Do these benefits align with learning goals?\nCan you identify potential harms to the validity of assessment of using AI in making the coursework?\nWould you have liked to be able to use AI in the coursework? Perhaps more freely than allowed? Why or why not?\nDo you think that the current interaction of aims with assessment methods creates inequalities in the student population? If so, how? And do you think that the assessment methods are equally fair to all students?\nDo you see a potential for new assessment methodologies for your course that would fit the course and the student population?\n\n2. Now with your group, discuss the above, for example by considering the following questions:\n\nWhat do you think are the potential benefits for students of using AI to complete coursework?\nWhat do you think are the potential harms for students of using AI to complete coursework?\nCan you identify assessment modes that are more vulnerable to the use of AI than others?\nCan you identify assessment modes that are not vulnerable to the use of AI?\nWhat type of learning goals or testing/course aims do you percieve as most vulnerable to the use of AI? For example, writing computer code, writing essays, solving math problems, etc.\nHave you identified any potential inequalities in the student population that arise from the use of AI in coursework?\nHave you identified any assessment methodologies that would alleviate some or all of the percieved issues?\n\n3. Now, as a group, aggregate your findings and write a letter to the Director of Education. In this letter, you should\n\nreflect on whether you think AI tools create inequalities with respect to grading of student’s work\nargue both the perceived potential for higher/lower learning gains for students, as well as potential for improvement towards the validity of grading of student’s work\nreflect on whether you think that our current learning goals/course aims are still valid in the light of AI tools\npropose any new assessment methodology or procedure that you think would be more suitable for certain courses, learning goals or allow for fairer grading of student’s work\nany other business that came up in your discussion that you think is important to mention\n\nYou should aim to write the letter in a critical but constructive manner. It is more helpful to guide a call for action with examples and proposals, then to criticize current practices. Perhaps it is helpful to imagine what you would do if you were the Director of Education.\n\n\n\nIn the last 3 years, the development of generative artificial intelligence (AI) has taken a steep rise. But AI is no new idea. Ever sinds Alan Turing’s seminal lecture on the automatic computing machine (Turing 2004), computer scientists have worked towards the realization of artificial intelligence. Even AI chatbots are not new. In 1966, Joseph Weizenbaum developed the psychotherapist chatbot ELIZA (Weizenbaum 1966). I am not going to give an overview of the history of AI, as others have already created a far better overview than I could ever create - see e.g. this link, Wikipedia or this overview. Bottom line, ever since the development of GitHub Copilot in 2021, the field of generative AI has rapidly become accessible to a broader audience. This development has a direct impact on higher education, as the straightforward access for student and teacher populations to generative AI has the potential to impact education, research and policy. Developments in generative AI also have the means to create new opportunities and - unfortunately - new divides.\nIn this challenge, I would like to focus on the hidden impact of AI tools in education. While the use of AI tools in education is often framed as a positive development, there are also negative consequences that are often overlooked.\n\nImpact\nThere are numerous ways that the increasing use and implementations of AI tools may impact our lives. In this section I will discuss some forms of direct and indirect impact of AI tools on human life.\n\nEthical impact\nMany people are unaware of the ethical implications of using AI tools, apart from presenting AI-generated work as your own product. AI tools are often trained on data that is biased or incomplete, which can lead to biased or incorrect results. AI tools have demonstrated to yield inaccurate, incomplete or false information. This can happen when the AI tool perceives patterns or objects that are nonexistent, resulting in nonsensical or inaccurate output, often referred to as hallucinations (Ji et al. 2023; Alkaissi and McFarlane 2023; Athaluri et al. 2023), although some resistance against that term has emerged (Østergaard and Nielbo 2023). It is important to always use multiple sources to verify any bit of information. As a user of AI tools you should accept that only you are responsible for using, interpreting and curating AI-generated output.\nThe age-old adage garbage in, garbage out holds here too: old biases and ideas may unwantedly be perpetuated by AI tools, thereby fueling divides, biases and stereotypes that we have tried so hard to remove.\n\n\nLegal impact\nMany people are unaware of the legal implications of using AI tools. AI tools are often trained on data that is copyrighted or patented, which can lead to legal issues if the data is used without permission. To avoid such issues, when interacting with AI tools, users should protect intellectual property rights and copyright. When submitting prompts as input to AI tools it is paramount to ensure that\n\nyou are allowed to share the information in the prompt or have explicit permission\nyou are not infringing on any right associated with the information in the prompt\n\nLikewise, it is important to realize that no intellectual property or copyright may be infringed with using the output of the AI tool. The training of the AI tool happened on a large set of data; some of that data may have been used illegitimately. By using AI generated output you may plagiarize existing work or otherwise infringe on intellectual property rights.\nThis is a tricky scenario, as the nontransparent training of AI tools makes it challenging to prove that no IP is infringed with the realized output. However, one could argue that embedding AI tools in a normal scientific knowledge discovery scenario would minimize the change of any infringement. Such a route would result in a process where information from multiple sources is processed and curated by an actual human.\n\n\nEnvironmental impact\nMany users are unaware of the impact that contemporary AI tools may have on the environment. Together with e.g. cloud storage and e-mail traffic, AI tools constitute a hidden carbon footprint that often escapes our awareness. While it is not as apparent as airline travel, the impact of using AI tools may be far greater than you think and decarbonizing the energy usage alone is not enough to sustainably implement AI tools in our everyday life (Berthelot et al. 2024). It is estimated that using generative AI Tools currently accounts for up to 25 times the energy emissions that are generated from training the models (Chien et al. 2023). While the environmental impact can ultimately be significantly lowered by moving from server-based generative AI to on-chip generative AI, there will always be a cost of using AI tools. Many people have thought about how AI will impact human life and Hollywood has monetized its threat to human existence. Not many may have realized that our lives may currently be at risk through AI-induced global warming.\n\n\nSocial impact\nIn recent years many idealistic promises have been made about the potential of AI to improve human life. Widespread access for everyone to AI models and tools has been said to contribute to equality, allowing everybody to access high quality information and interact witht the same technology. This widespread access, however, also allows for non-just purposes. AI tools are neutral and can be used to harm people and spread misinformation. AI tools can be used to manipulate people, to deepen existing biases, to incite hate speech or to discriminate against people, evidence of which has been found in the use of AI tools in hiring processes and the potential for election manipulation (Baldassarre et al. 2023; Lytton 2024; Ali Swenson and Kelvin Chan 2024; Mekela Panditharatne and Noah Giansiracusa 2023). Aside from the potential for AI to incite societal harm on a fundamental level, it can also disrupt society on a more existential level. The widespread use of AI tools may lead to a loss of jobs, as AI tools can automate tasks that were previously done by humans. This can lead to a loss of income and a decrease in the quality of life for many people. The zeitgeist of contemporary AI tools pairs a strong call for regulatory action with a warning for over-regulation.\n\n\nHuman rights and labor rights\nThere is evidence that the workers who curate these models are treated unfairly or even inhumanely by their employers. This interview also paints a good picture of how and where AI work can harm people. This means that the use of AI tools may not only effect the networks of the people who use them, but also have an effect on the people who curate the models behind these tools.\n\n\n\nDefinition of Challenge\nIn this challenge I would like to invite you to reflect on the hidden impact of AI tools in higher education. The aim of this challenge is to raise awareness of the potential negative consequences of using AI tools in education and to encourage you to think critically about the ethical, legal, environmental, social, and human rights implications of using AI tools.\n1. Discuss the above impact domains in your group. Let the following talking points guide your discussion.\n\nWhere do you see potential in your daily work for AI tools to have either a positive or a negative impact on your life?\nHow do you think AI tools can be used to improve your daily work?\nDo you think that AI tools can be used to harm people or spread misinformation? Do you have examples of that happening?\nDo you use AI tools in your daily work? Why do you (not) use them?\nAre there ways to mitigate the above outlined potential negative consequences of using AI tools in your daily work?\nDo you feel that the responsibility of mitigating the potential negative consequences of using AI tools lies with the individual user, the organization, or the government?\nDo you feel that the positive benefits of AI tools outweigh the potential negative consequences?\nWould your answer to the previous question change if you consider the current state of AI tools als a transition phase to a more advanced state where all negative impact is mitigated?\nDo you think that our university should take action to mitigate the potential negative consequences of using AI tools in education? If so, what actions do you think the university should take?\nDo you think that the potential negative consequences of using AI tools in education are being adequately addressed by the university? If not, what do you think the university should do to address these consequences?\n\n2. After discussing these questions, write a letter of advice to the UU Executive board. In this letter, you should:\n\nStart with the potential positive impact of AI tools in society in general and education in particular\nReflect on the potential negative consequences of using AI tools in our institution, highlighting the respective domain impact as discussed in your group\nArgue whether you think the university should take action to mitigate these consequences\nPropose any actions that you think the university should take to mitigate the potential negative consequences of using AI tools in education\nConsider any other business that came up in your discussion that you feel important to mention\n\nTry to write the letter in a critical but constructive manner. It is more helpful to guide a call for action with examples and proposals, then to criticize current practices or lack thereof. Perhaps it is helpful to imagine what you would find most helpful to motivate yourself to act if you were a member of the Executive Board.\n\n\n\n\n\n\n\n\n\nReferences\n\nAbbas, Muhammad, Farooq Ahmed Jam, and Tariq Iqbal Khan. 2024. “Is It Harmful or Helpful? Examining the Causes and Consequences of Generative AI Usage Among University Students.” International Journal of Educational Technology in Higher Education 21 (1): 10. https://doi.org/10.1186/s41239-024-00444-7.\n\n\nAli Swenson, and Kelvin Chan. 2024. “Election Disinformation Takes a Big Leap with AI Being Used to Deceive Worldwide.” AP News. https://apnews.com/article/artificial-intelligence-elections-disinformation-chatgpt-bc283e7426402f0b4baa7df280a4c3fd.\n\n\nAlkaissi, Hussam, and Samy I McFarlane. 2023. “Artificial Hallucinations in ChatGPT: Implications in Scientific Writing.” Curēus 15 (2).\n\n\nAthaluri, Sai Anirudh, Sandeep Varma Manthena, VSR Krishna Manoj Kesapragada, Vineel Yarlagadda, Tirth Dave, and Rama Tulasi Siri Duddumpudi. 2023. “Exploring the Boundaries of Reality: Investigating the Phenomenon of Artificial Intelligence Hallucination in Scientific Writing Through ChatGPT References.” Curēus 15 (4).\n\n\nBaldassarre, Maria Teresa, Danilo Caivano, Berenice Fernandez Nieto, Domenico Gigante, and Azzurra Ragone. 2023. “The Social Impact of Generative AI: An Analysis on ChatGPT.” In Proceedings of the 2023 ACM Conference on Information Technology for Social Good, 363–73. GoodIT ’23. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/3582515.3609555.\n\n\nBerthelot, Adrien, Eddy Caron, Mathilde Jay, and Laurent Lefèvre. 2024. “Estimating the Environmental Impact of Generative-AI Services Using an LCA-based Methodology.” In CIRP LCE 2024 - 31st Conference on Life Cycle Engineering, 1–10. Turin, Italy.\n\n\nChien, Andrew A, Liuzixuan Lin, Hai Nguyen, Varsha Rao, Tristan Sharma, and Rajini Wijayawardana. 2023. “Reducing the Carbon Impact of Generative AI Inference (Today and in 2035).” In Proceedings of the 2nd Workshop on Sustainable Computer Systems. HotCarbon ’23. New York, NY, USA: Association for Computing Machinery. https://doi.org/10.1145/3604930.3605705.\n\n\nHabib, Sabrina, Thomas Vogel, Xiao Anli, and Evelyn Thorne. 2024. “How Does Generative Artificial Intelligence Impact Student Creativity?” Journal of Creativity 34 (1): 100072. https://doi.org/10.1016/j.yjoc.2023.100072.\n\n\nHeersmink, Richard. 2024. “Use of Large Language Models Might Affect Our Cognitive Skills.” Nature Human Behaviour, March, 1–2. https://doi.org/10.1038/s41562-024-01859-y.\n\n\nJi, Ziwei, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang, Andrea Madotto, and Pascale Fung. 2023. “Survey of Hallucination in Natural Language Generation.” Acm Computing Surveys 55 (12). https://doi.org/10.1145/3571730.\n\n\nKNAW, NFU, NWO, TO2-Federatie, Vereniging Hogescholen, and VSNU. 2018. “Nederlandse gedragscode wetenschappelijke integriteit.” Data Archiving and Networked Services (DANS). https://doi.org/10.17026/DANS-2CJ-NVWU.\n\n\nKumar, Rahul. 2023. “Faculty Members’ Use of Artificial Intelligence to Grade Student Papers: A Case of Implications.” International Journal for Educational Integrity 19 (1): 9.\n\n\nLytton, Charlotte. 2024. “AI Hiring Tools May Be Filtering Out the Best Job Applicants.” https://www.bbc.com/worklife/article/20240214-ai-recruiting-hiring-software-bias-discrimination.\n\n\nMekela Panditharatne, and Noah Giansiracusa. 2023. “How AI Puts Elections at Risk — And the Needed Safeguards  Brennan Center for Justice.” https://www.brennancenter.org/our-work/analysis-opinion/how-ai-puts-elections-risk-and-needed-safeguards.\n\n\nØstergaard, Søren Dinesen, and Kristoffer Laigaard Nielbo. 2023. “False Responses from Artificial Intelligence Models Are Not Hallucinations.” Schizophrenia Bulletin 49 (5): 1105–7. https://doi.org/10.1093/schbul/sbad068.\n\n\nRoschelle, Jeremy, James Lester, and Judi Fusco. 2020. “AI and the Future of Learning: Expert Panel Report.” Digital Promise. Digital Promise.\n\n\nTuring, Alan. 2004. “Lecture on the Automatic Computing Engine (1947).” In The Essential Turing. Oxford University Press. https://doi.org/10.1093/oso/9780198250791.003.0015.\n\n\nUtrecht University. 2024a. “Codes of Conduct - Organisation - Utrecht University.” https://www.uu.nl/en/organisation/about-us/codes-of-conduct.\n\n\n———. 2024b. “Generative AI - Education - Utrecht University.” https://www.uu.nl/en/education/education-at-uu/teaching/generative-ai.\n\n\nWeizenbaum, Joseph. 1966. “ELIZA—a Computer Program for the Study of Natural Language Communication Between Man and Machine.” Communications of The Acm 9 (1): 36–45. https://doi.org/10.1145/365153.365168."
  },
  {
    "objectID": "lecture.html#disclaimer",
    "href": "lecture.html#disclaimer",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "Disclaimer",
    "text": "Disclaimer\nThis presentation is a collection of my thoughts and opinions. It does not necessarily represent the views of Utrecht University or the USO Consortium AI in Higher Education.\nThese materials are generated by Gerko Vink, who holds the copyright. The intellectual property belongs to Utrecht University. Images are either directly linked, or generated with DALL-E. That said, there is no information in this presentation that exceeds legal use of copyright materials in academic settings, or that should not be part of the public domain.\nYou may use any and all content in this presentation - including my name - and submit it to generative AI tools, with the following exception:\n\nYou must ensure that the content is not used for further training of the model \n\nSource:\n\nwww.gerkovink.com/think\ngithub.com/gerkovink/think"
  },
  {
    "objectID": "lecture.html#first-of-all",
    "href": "lecture.html#first-of-all",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "First of all",
    "text": "First of all\n\n\n\n\n\n\nEducation is a universal right\n\n\nEveryone has the right to education. Education shall be free, at least in the elementary and fundamental stages. Elementary education shall be compulsory. Technical and professional education shall be made generally available and higher education shall be equally accessible to all on the basis of merit  Source: Universal Declaration of Human Rights as declared by the United Nations in 1948."
  },
  {
    "objectID": "lecture.html#what-is-generative-ai",
    "href": "lecture.html#what-is-generative-ai",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "What is Generative AI?",
    "text": "What is Generative AI?\nGenerative AI refers to a subset of artificial intelligence technologies capable of generating new content, ideas, or data that resemble human-like outputs.\n\nGenerative AI operates through advanced machine learning models, particularly deep learning networks.\nThese models are trained on large amounts of data in a specific domain (e.g., text, images, video) and can then generate new outputs based on the patterns and features they have learned.\n\nSome common examples of generative AI technologies include:\n\nChatbots and virtual tutors: AI-driven chatbots can provide personalized tutoring, answering student questions and offering explanations on a wide range of subjects.\nContent creation tools: Tools like GPT (Generative Pre-trained Transformer) can assist in creating educational content, generating lecture notes, or drafting exam questions based on certain criteria.\nAutomated essay scoring and feedback: AI models can grade essays and provide feedback to students on their writing."
  },
  {
    "objectID": "lecture.html#how-do-ai-tools-work-in-10-steps",
    "href": "lecture.html#how-do-ai-tools-work-in-10-steps",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "How Do AI Tools Work (in 10 steps)?",
    "text": "How Do AI Tools Work (in 10 steps)?\n\nMachine learning enables computers to learn from data, identify patterns, and make decisions with varying levels of human intervention.\nMachine learning methods often work by means of training, for example to perform a single task or set of tasks.\nSome forms of models are not specifically programmed to perform certain tasks and learn withouth human intervention.\nThe domain of machine learning that focuses on such human brain-like deep learning strategies is called neural networks (NNs).\nTransformers (Vaswani et al. 2017) are a type of neural network that have advanced deep learning, particularly in the domain of natural language processing.\nInstead of modeling words one after another, transformers can look at whole sentences or paragraphs at once and take the context of text into account.\nIt is not hard to imagine that contextual understanding allows for better learning and more flexible applications.\n\n\nVaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., … & Polosukhin, I. (2017).Attention is all you need. Advances in neural information processing systems, 30."
  },
  {
    "objectID": "lecture.html#how-do-ai-tools-work-in-10-steps-1",
    "href": "lecture.html#how-do-ai-tools-work-in-10-steps-1",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "How Do AI Tools Work (in 10 steps)?",
    "text": "How Do AI Tools Work (in 10 steps)?\n\n\n\n\nGenerative AI tools, such as Gemini, chatGPT or GitHub Copilot are applications of transformers.\nThese tools have been trained on extremely large amounts of data (mostly text) and have learned from the structure, meaning and nuances of the language.\nAfter training, these tools can generate new text that both coherent an contextually relevant.  Don’t be fooled! It’s just a prediction model\n\n\n \n\n\n\nImage prompt: generate an image of an AI in android form training with weights in a gym"
  },
  {
    "objectID": "lecture.html#who-develops-generative-ai-tools",
    "href": "lecture.html#who-develops-generative-ai-tools",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "Who develops generative AI tools",
    "text": "Who develops generative AI tools\n\nGenerative AI technologies are often developed by publicly traded companies with:\n\nDeep pockets\nShareholders\nMotives and goals that may diverge from academic or public interests\n\nThese technologies also require significant computing resources for training and operation\n\nThis skews access and development to those with substantial resources.\nIf you feel sad or overwhelmed by the low sense of control, read Choose Your Weapon: Survival Strategies for Depressed AI Academics\n\n\n\nTogelius, J., & Yannakakis, G. N. (2024). Choose Your Weapon: Survival Strategies for Depressed AI Academics [Point of View]. Proceedings of the IEEE, 112(1), 4-11."
  },
  {
    "objectID": "lecture.html#impact-on-education",
    "href": "lecture.html#impact-on-education",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "Impact on education",
    "text": "Impact on education\nThere is a finite number of options for dealing with generative AI in education. These options translate to the following stages of AI grief:\n\n\n\nIgnore the existence of generative AI\nForbid the use of generative AI\nCircumnavigate generative AI by using offline assessment modes like pen/paper exams or oral exams\nTest around Let students perform tasks that generative AI struggles with\nEmbrace generative AI and allow it in course work\nRethink the way we assess students and develop new assessment methodologies"
  },
  {
    "objectID": "lecture.html#futureproof-education",
    "href": "lecture.html#futureproof-education",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "Futureproof education?",
    "text": "Futureproof education?\n\n\n\n\n\n\nCould it be\n\n\nThat our defined learning goals, our evaluations and the skills that we teach are not aligned with the future professional needs for our student body?"
  },
  {
    "objectID": "lecture.html#ai-in-assessment",
    "href": "lecture.html#ai-in-assessment",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "AI in assessment",
    "text": "AI in assessment\nIt is crucial to think about proper assessment designs for an AI-enabled student body.\nHere are some links that I find useful:\n\nUCL: Designing assessments in and AI enabled world\nUNF: ChatGPT-proof your course\nUU: Can you still use take-home exams and essays?\nBower, M., Torrington, J., Lai, J.W.M. et al. (2024) How should we change teaching and assessment in response to increasingly powerful generative Artificial Intelligence? Outcomes of the ChatGPT teacher survey. Educ Inf Technol.\nTILAPIA tool by Phil Newton & ChatGPT\nUU: Chatbots in education: friend or foe"
  },
  {
    "objectID": "lecture.html#impact-of-ai-on-cognitive-performance",
    "href": "lecture.html#impact-of-ai-on-cognitive-performance",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "Impact of AI on Cognitive Performance",
    "text": "Impact of AI on Cognitive Performance\n\n\nHeersmink, R. Use of large language models might affect our cognitive skills. Nat Hum Behav (2024)"
  },
  {
    "objectID": "lecture.html#impact-of-ai-on-cognitive-performance-1",
    "href": "lecture.html#impact-of-ai-on-cognitive-performance-1",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "Impact of AI on Cognitive Performance",
    "text": "Impact of AI on Cognitive Performance\n\n\n\n\n\n\n\n\nHabib, S., Vogel, T., Anli, X., & Thorne, E. (2024). How does generative artificial intelligence impact student creativity?. Journal of Creativity, 34(1), 100072."
  },
  {
    "objectID": "lecture.html#impact-of-ai-on-cognitive-performance-2",
    "href": "lecture.html#impact-of-ai-on-cognitive-performance-2",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "Impact of AI on cognitive performance",
    "text": "Impact of AI on cognitive performance\n \n\nAbbas, M., Jam, F.A. & Khan, T.I. Is it harmful or helpful? Examining the causes and consequences of generative AI usage among university students.  Int J Educ Technol High Educ 21, 10 (2024)."
  },
  {
    "objectID": "lecture.html#impact-on-society",
    "href": "lecture.html#impact-on-society",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "Impact on society",
    "text": "Impact on society\n\nThere is also a societal impact of generative AI technologies\n\nThey can create divides and inequality\nThere is evidence that the workers who curate these models are treated unfairly or even inhumanely by their employers. This interview from last month also paints a good picture of how and where AI work can harm people.\n\nThe energy consumption required for training generative models contributes to carbon emissions.\n\nThis also holds for interacting with and applying these models\nThere is already a larger than necessary hidden carbon footprint\n\nThe Dunning-Kruger effect"
  },
  {
    "objectID": "lecture.html#current-at-our-university",
    "href": "lecture.html#current-at-our-university",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "Current at our university",
    "text": "Current at our university\n\nUU policy\nUMCU: Guidelines for GSLS students\nUMCU: GenAI guidelines for research projects for students and supervisors"
  },
  {
    "objectID": "lecture.html#towards-responsible-genai-use",
    "href": "lecture.html#towards-responsible-genai-use",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "Towards responsible genAI use",
    "text": "Towards responsible genAI use\nI believe that we should demand from the UU community to follow these simple steps when using generative AI tools:\n\nMinimize the use of AI tools, as they are (currently) environmentally unfriendly\nDon’t input confidential or personal information\nDon’t input information that violates IP or copyright\nDon’t violate IP with using output from the tool\nConfirm the output accuracy\nCheck the tool output for bias\nDisclose the use of AI tools in your work\nDon’t do naughty or unjust things with AI tools\nAsk the tool not to use input for training\nOpen the content you produce by using AI tools as much as possible with permissive licenses\n\nIf in doubt about any of the above, don’t use generative AI tools.\nFor teachers: Put a disclaimer on your materials that governs what is or is not allowed when using generative AI tools."
  },
  {
    "objectID": "lecture.html#enhancing-learning-with-ai",
    "href": "lecture.html#enhancing-learning-with-ai",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "Enhancing Learning with AI",
    "text": "Enhancing Learning with AI\n\nPersonalized Learning Pathways: Generative AI tools are paving the way for personalized education, adapting in real-time to the learning pace and styles of individual students. This leads to a more engaging and effective learning experience, tailored to the needs and strengths of each learner.\nInteractive Content Generation: These tools can produce dynamic educational content, including interactive simulations, customized quizzes, and virtual labs, making complex subjects more accessible and engaging for students.\nImproved Engagement and Motivation: By providing instant feedback and fostering a more interactive learning environment, generative AI tools have the potential to increase student engagement and motivation, crucial factors for successful learning outcomes.\nAugmented Creativity and Problem-Solving: With the capability to suggest multiple perspectives on a given topic, AI can enhance students’ critical thinking and creativity, encouraging them to explore novel solutions to problems.\nAccess to Quality Education: Generative AI can democratize education by offering high-quality, personalized learning experiences to students in remote or underserved regions, breaking down geographical and socioeconomic barriers to education.\nSupport for Instructors: By automating administrative tasks and offering insights into student performance, AI tools allow educators to devote more time to teaching and personalized interaction with students, enhancing the overall educational experience.\n\n\nGenerated with ChatGPT"
  },
  {
    "objectID": "lecture.html#enhancing-learning-with-ai-1",
    "href": "lecture.html#enhancing-learning-with-ai-1",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "Enhancing Learning with AI",
    "text": "Enhancing Learning with AI\n\nPersonalized Learning Experiences: Generative AI can create customized educational content that suits the learning pace and style of individual students. This approach has been shown to improve engagement and comprehension in subjects ranging from mathematics to language learning.\nEnhanced Research and Writing Assistance: For academic research and writing, generative AI tools like automated literature review generators and citation managers have been developed.\nSimulations and Virtual Labs: In science and engineering education, generative AI has enabled the creation of highly detailed simulations and virtual labs.\nLanguage Learning and Enhancement: Generative AI has been particularly impactful in language learning, offering tools for automatic translation, conversation simulation, and pronunciation correction.\nFeedback and Assessment Tools: AI-driven assessment tools can provide instant feedback on student assignments, ranging from essays to complex problem sets.\nFacilitating Collaborative Learning: Generative AI can create scenarios or projects where students need to collaborate to find solutions, fostering soft skills like communication, teamwork, and problem-solving.\n\n\nAlso generated with ChatGPT, different prompt"
  },
  {
    "objectID": "lecture.html#when-asked-for-proof-of-enhanced-learning",
    "href": "lecture.html#when-asked-for-proof-of-enhanced-learning",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "When asked for proof of enhanced learning?",
    "text": "When asked for proof of enhanced learning?\n\nIntelligent Tutoring Systems and Sustainable Education: A systematic review has explored how AI supports sustainable education by changing teaching scenarios to more remote, virtual, and blended formats. It highlights the application of AI in analyzing learning behaviors, performance prediction, and personalized learning interventions. This integration aims for better adaptation to students’ real-time learning status and early assistance provision (source).\nAdaptive Learning Techniques for Personalized Education: The study discusses the use of e-TPCK, an adaptive electronic learning environment designed to support the development of student-teachers’ Technological Pedagogical Content Knowledge (TPCK) in a personalized manner. The e-TPCK system aims to engage learners in personalized learning experiences, addressing their diverse needs and preferences. (source).\nPersonalized Learning and Academic Assessment: The University of South Australia has developed learner profiles that provide real-time analysis of a student’s learning behaviors and wellbeing. This initiative aims to significantly improve teaching and learning quality by allowing educators to identify and respond to each child’s needs promptly. Furthermore, the OnTask project enhances academic experiences by providing personalized feedback and suggestions for better learning experiences. (source).\n\nPlease give me proof that AI enhances learning; I’d like to believe it so badly\n\nChatGPT: When asked for the proof of AI enhancing learning"
  },
  {
    "objectID": "lecture.html#bottomline",
    "href": "lecture.html#bottomline",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "Bottomline:",
    "text": "Bottomline:\nAI is supposed to enhance learning, but the evidence is still scarce. Promises are made about\n\npersonalized learning paths\nadaptive learning\nenhanced writing assistance\nimproved motivation\naccessibility to quality education\nsupport instructors\n\nOn top of that:\n\nAI is supposed to make education more inclusive\n\nthis is not the case, as the same level of AI is not accessible to all\nAI itself is not always inclusive, as it can be biased"
  },
  {
    "objectID": "lecture.html#students-and-teachers-expected-uses-of-ai",
    "href": "lecture.html#students-and-teachers-expected-uses-of-ai",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "Students and Teachers: Expected Uses of AI",
    "text": "Students and Teachers: Expected Uses of AI\nWe have seen the promises that have been made in the previous section. These promises assume that students and teachers will use AI in a certain way. Do they?\nTo realize the potential gains, students and teachers are supposed to take an active, knowledge driven approach to AI. This means that they should:\n\nengage actively\ncritically evaluate the output\nuse the output to enhance their learning experience"
  },
  {
    "objectID": "lecture.html#reality-check-how-ai-tools-are-actually-used",
    "href": "lecture.html#reality-check-how-ai-tools-are-actually-used",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "Reality Check: How AI Tools Are Actually Used",
    "text": "Reality Check: How AI Tools Are Actually Used"
  },
  {
    "objectID": "lecture.html#some-general-uu-survey-results",
    "href": "lecture.html#some-general-uu-survey-results",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "Some general UU survey results",
    "text": "Some general UU survey results\n\n1633 Students\n348 Teaching staff\nBA/MA balanced; few pre-master \n34.4% of teaching staff report not to use GenAl for educational purposes vs. only 13.4% of students\n68% of students use genAl for working with texts vs. 47% of staff\nMajority of respondents use GenAI for Brainstorming, Text Writing, Clarifying Questions, and Summarizing & Explaining Texts\nTeaching staff use it less for Research Design than students (40% vs. 11.9%)*\n18.5% of teaching staff report that they use to create study content and 26.9% for demonstration purposes in class"
  },
  {
    "objectID": "lecture.html#some-interesting-results",
    "href": "lecture.html#some-interesting-results",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "Some interesting results",
    "text": "Some interesting results\n\nBoth students and staff think that the use of GenAI tools for assignments is widespread among students use.\nLecturers seem to perceive students as not particularly knowledgeable about the use of GenAI\nStudents seem to perceive teachers as not particularly knowledgeable about the use of GenAI\nLecturers also think that their colleagues are not very knowledgeable about the us of GenAI.\nStudents don’t think it’s unethical to use GenAI in course work for support and assistance, or for generating a solution for even a small portion of an assignment. Staff views are a bit more varied, but not exact opposite.\nThere is a huge cry for literacy training in GenAl from both students and staff.\n7.1% of teaching staff report that they use it for grading/assessment of work (no significant differences between faculties detected)"
  },
  {
    "objectID": "lecture.html#can-ai-tools-be-used-for-grading",
    "href": "lecture.html#can-ai-tools-be-used-for-grading",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "Can AI Tools Be Used for Grading?",
    "text": "Can AI Tools Be Used for Grading?\nSure! I have done that in past, but I did not call it AI\nThere are a couple of domains where AI tools can be very helpful in grading:\n\nAutomated Essay Scoring (AES)\nCode evaluation and automated testing\n\nThe more structured language is, the easier it is for AI to optimize the language. This is very apparant in the field of programming, where AI can be used to generate all sorts of automated evaluations, code optimization, and unit tests."
  },
  {
    "objectID": "lecture.html#how-aes-works",
    "href": "lecture.html#how-aes-works",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "How AES Works",
    "text": "How AES Works\n\nTraining: AES systems are trained on a dataset of essays that have been graded by human experts. The system learns to recognize the qualities and characteristics that correspond to various grades.\nFeature Extraction: The AES algorithms analyze essays for a range of features, including grammar, syntax, vocabulary, sentence structure, and sometimes even the coherence and logic of the argument. The sophistication of feature analysis can vary widely among systems.\nScoring: Once an essay is submitted, the AES system applies the model it has learned to evaluate the unseen essay’s features. It then assigns a score based on its training on previously graded essays.\nFeedback: Some AES systems can also provide feedback to students, identifying areas for improvement or strengths in their writing.\n\nThis is a completely different scenario from entering student work into generative AI tools to generate output for grading student work!"
  },
  {
    "objectID": "lecture.html#cons-of-ai-assisted-grading",
    "href": "lecture.html#cons-of-ai-assisted-grading",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "Cons of AI-Assisted Grading",
    "text": "Cons of AI-Assisted Grading\nMuch like with AES, there are some limitations and potential drawbacks to using AI tools for grading:\n\nLanguage is complex; can contemporary AI fully grasp the nuance that a human grader would pick up?\nBias in the training data can lead to biased grading outcomes.\nAI tools may struggle with creativity, originality, or unconventional approaches that human graders can appreciate.\nHow does AI treat continuation errors in exams?\nWould you feel satisfied if your work was evaluated by an AI reviewer? Or if an AI would process and respond to your assessment and development portfolio?\nIsn’t student work protected by intelectual property and copyright?\n\nAs a statistician I can argue that using AI tools for grading opens the door to a class of potential errors that might go unnoticed."
  },
  {
    "objectID": "lecture.html#is-it-a-good-idea-to-use-ai-in-grading",
    "href": "lecture.html#is-it-a-good-idea-to-use-ai-in-grading",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "Is It a Good Idea to Use AI in Grading?",
    "text": "Is It a Good Idea to Use AI in Grading?\n\n\nKumar, R. Faculty members’ use of artificial intelligence to grade student papers: a case of implications. Int J Educ Integr 19, 9 (2023)"
  },
  {
    "objectID": "lecture.html#student-rights-in-the-ai-era-classroom",
    "href": "lecture.html#student-rights-in-the-ai-era-classroom",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "Student rights in the AI-Era Classroom",
    "text": "Student rights in the AI-Era Classroom\n\n\n\n\n\n\nHuman contact is a right\n\n\nEvery student has the right to be educated and graded by a human being. That right also includes the right to know a priori to what extend AI is used\n\nin creating the educational materials,\nin providing feedback,\nin grading student work.\n\nEvery student has the right to refuse interaction or any other involvement with an AI for their coursework."
  },
  {
    "objectID": "lecture.html#conclusion",
    "href": "lecture.html#conclusion",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "Conclusion",
    "text": "Conclusion\nMinimize the use of AI tools, and when you do use them, do so responsibly.\nGenerative AI can be a great companion in a knowledge discovery journey, but it is not a replacement for scientific rigor, active reading, critical thinking and human creativity.\nContemporary AI should always be viewed as a complement to human actions rather than a replacement.\nBe as transparant about the use of AI tools in your work as you would require others to be. Also, make sure that you are not violating any rights or laws.\n\n\n\n\n\n\nThe only way to sustainable embedding of generative AI in academia is to ensure a sense of community and collective ownership of responsible AI practice.\nThis requires a shared responsibility that requires the active participation of all involved, whereby we hold ourselves and each other accountable for our actions."
  },
  {
    "objectID": "lecture.html#consortium-uso-at-utrecht-university",
    "href": "lecture.html#consortium-uso-at-utrecht-university",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "Consortium USO at Utrecht University",
    "text": "Consortium USO at Utrecht University\n\n\n\n\n\nGerko Vink - Methods & Statistics @ UU"
  },
  {
    "objectID": "lecture.html#final-thoughts",
    "href": "lecture.html#final-thoughts",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "Final thoughts",
    "text": "Final thoughts\n\njoin the consortium\ntalk to each other\ntalk to me\n\nFollow the growing collection of information in a more structured resource at www.gerkovink.com/ai\n\n\n\n\nGerko Vink - Methods & Statistics @ UU"
  },
  {
    "objectID": "lecture.html#but",
    "href": "lecture.html#but",
    "title": "The Use and Misuse of Generative AI in Academic Education",
    "section": "But",
    "text": "But\n\nSource: Kevin Roose for the NY times"
  }
]